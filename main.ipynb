{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T21:28:59.767821Z",
     "start_time": "2025-10-31T21:28:59.760803Z"
    }
   },
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "import os\n",
    "INPUT_VIDEO = str(Path(\"crowd.mp4\").resolve())\n",
    "OUTPUT_VIDEO = str(Path(\"crowd_1.mp4\").resolve())\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CONF_THRESH = 0.5\n",
    "PERSON_CLASS_ID = 1\n",
    "SCALE = 2.0\n",
    "DOWNSAMPLE_FOR_SPEED = 1\n",
    "INPUT_FRAMES_DIR = \"frames\"\n",
    "ANNOTATION_FILE = \"instances_Validation.json\"\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 5\n",
    "LR = 1e-4\n",
    "print(DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:29:00.953140Z",
     "start_time": "2025-10-31T21:29:00.945298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VideoFramesDataset(Dataset):\n",
    "    def __init__(self, frames_dir, annotation_file, transform=None):\n",
    "        self.frames_dir = frames_dir\n",
    "        self.transform = transform\n",
    "        with open(annotation_file, \"r\") as f:\n",
    "            self.coco = json.load(f)\n",
    "\n",
    "        self.images = {im['id']: im for im in self.coco['images']}\n",
    "        self.annotations = {}\n",
    "        for ann in self.coco['annotations']:\n",
    "            self.annotations.setdefault(ann['image_id'], []).append(ann)\n",
    "\n",
    "        self.ids = list(self.images.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_info = self.images[img_id]\n",
    "        img_path = os.path.join(self.frames_dir, img_info['file_name'])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if SCALE != 1.0:\n",
    "            height, width = int(img.shape[0]*SCALE), int(img.shape[1]*SCALE)\n",
    "            img = cv2.resize(img, (width, height))\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in self.annotations.get(img_id, []):\n",
    "            x, y, w, h = ann['bbox']\n",
    "            if SCALE != 1.0:\n",
    "                x, y, w, h = x * SCALE, y * SCALE, w * SCALE, h * SCALE\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann['category_id'])\n",
    "\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes,\n",
    "                  \"labels\": labels,\n",
    "                  \"image_id\": torch.tensor([img_id]),\n",
    "                  \"image_name\": img_info['file_name']\n",
    "                }\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ],
   "id": "7b4153e335b6be6",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:29:02.059892Z",
     "start_time": "2025-10-31T21:29:01.943367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "dataset = VideoFramesDataset(INPUT_FRAMES_DIR, ANNOTATION_FILE, transform=transform)\n",
    "\n",
    "train_size = int(0.3 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ],
   "id": "1a375df9ff32c463",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:29:05.792752Z",
     "start_time": "2025-10-31T21:29:05.320847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=True, progress=True)\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "    in_features, num_classes=2\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model.train()\n"
   ],
   "id": "2fcc867466682dda",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.to(DEVICE)"
   ],
   "id": "d48be0d057f4cbea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:29:09.403109Z",
     "start_time": "2025-10-31T21:29:09.398876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=LR, weight_decay=1e-4)"
   ],
   "id": "cd26c63b63543b84",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T22:18:50.360125Z",
     "start_time": "2025-10-31T22:18:50.340554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "id": "987ccca7c584c04a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\festa\\PycharmProjects\\object_detect\\gpu-env\\Scripts\\python.exe\n"
     ]
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:31:46.650419Z",
     "start_time": "2025-10-31T21:29:09.948969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = list(img.to(DEVICE) for img in imgs)\n",
    "\n",
    "        #targets = [{k: v.to(DEVICE) for k, v, n, m in t.items()} for t in targets]\n",
    "        targets = [\n",
    "                {k: v.to(DEVICE) for k, v in t.items() if k in [\"boxes\", \"labels\"]}\n",
    "                for t in targets\n",
    "                  ]\n",
    "        loss_dict = model(imgs, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += losses.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {avg_loss:.4f}\")"
   ],
   "id": "85fa281d17d86dc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.2420\n",
      "Epoch [2/5], Loss: 0.9768\n",
      "Epoch [3/5], Loss: 0.8599\n",
      "Epoch [4/5], Loss: 0.7826\n",
      "Epoch [5/5], Loss: 0.7281\n"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:32:56.571889Z",
     "start_time": "2025-10-31T21:31:46.785062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, (images, targets) in enumerate(val_loader):\n",
    "    images = list(img.to(DEVICE) for img in images)\n",
    "    outputs = model(images)\n",
    "\n",
    "    for j, output in enumerate(outputs):\n",
    "        image_id = targets[j]['image_id'] if 'image_id' in targets[j] else val_loader.dataset.ids[j]\n",
    "\n",
    "        for box, label, score in zip(output['boxes'], output['labels'], output['scores']):\n",
    "            x1, y1, x2, y2 = box.cpu().detach().numpy()\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "\n",
    "            results.append({\n",
    "                \"image_id\": image_id.item(),\n",
    "                \"category_id\": int(label.cpu().detach().numpy()),\n",
    "                \"bbox\": [float(x1), float(y1), float(w), float(h)],\n",
    "                \"score\": float(score.cpu().detach().numpy())\n",
    "            })\n",
    "\n",
    "with open(\"results_val.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ],
   "id": "1f24f6de9a5b1dc",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:32:56.750369Z",
     "start_time": "2025-10-31T21:32:56.746368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_transparent_box(img, xyxy, label_text, score, box_color=(0,255,0), alpha=0.25):\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    overlay = img.copy()\n",
    "\n",
    "    cv2.rectangle(overlay, (x1, y1), (x2, y2), box_color, -1)\n",
    "    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n",
    "\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "\n",
    "    text = f\"{label_text}: {score:.2f}\"\n",
    "    (tw, th), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    tx, ty = x1, max(0, y1 - 6)\n",
    "\n",
    "    cv2.rectangle(img, (tx, ty - th - baseline), (tx + tw, ty + baseline), (0,0,0), -1)\n",
    "    cv2.putText(img, text, (tx, ty - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)"
   ],
   "id": "59b5a0b8ce9c7a87",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:32:56.756805Z",
     "start_time": "2025-10-31T21:32:56.753423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def non_max_suppression(boxes, scores, iou_threshold=0.5):\n",
    "    idxs = torchvision.ops.nms(torch.tensor(boxes).float(), torch.tensor(scores).float(), iou_threshold)\n",
    "    return idxs.numpy()"
   ],
   "id": "5e4d27dea837e626",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:32:56.797366Z",
     "start_time": "2025-10-31T21:32:56.762317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Не удалось открыть видео {INPUT_VIDEO}\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * SCALE)\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * SCALE)\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps / DOWNSAMPLE_FOR_SPEED, (width, height))\n",
    "frame_idx = 0\n",
    "total_time = 0.0\n",
    "processed = 0"
   ],
   "id": "c8add484d85282f2",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:39:28.621666Z",
     "start_time": "2025-10-31T21:32:56.801901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coco_boxes = []\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "\n",
    "        if SCALE != 1.0:\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        tensor = transform(img_rgb).to(DEVICE)\n",
    "\n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            outputs = model([tensor])\n",
    "        t1 = time.time()\n",
    "        elapsed = t1 - t0\n",
    "        total_time += elapsed\n",
    "        processed += 1\n",
    "\n",
    "        out_dict = outputs[0]\n",
    "        boxes = out_dict['boxes'].cpu().numpy()\n",
    "        labels = out_dict['labels'].cpu().numpy()\n",
    "        scores = out_dict['scores'].cpu().numpy()\n",
    "\n",
    "        mask_person = labels == PERSON_CLASS_ID\n",
    "        boxes = boxes[mask_person]\n",
    "        scores = scores[mask_person]\n",
    "\n",
    "        keep_mask = scores >= CONF_THRESH\n",
    "        boxes = boxes[keep_mask]\n",
    "        scores = scores[keep_mask]\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            keep_idxs = non_max_suppression(boxes, scores, iou_threshold=0.5)\n",
    "            boxes = boxes[keep_idxs]\n",
    "            scores = scores[keep_idxs]\n",
    "\n",
    "            for bb, sc in zip(boxes, scores):\n",
    "                x1, y1, x2, y2 = bb\n",
    "                draw_transparent_box(frame, (x1, y1, x2, y2), \"person\", float(sc), box_color=(0,200,0), alpha=0.18)\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                coco_boxes.append({\"image_id\": frame_idx,\n",
    "                                    \"category_id\": PERSON_CLASS_ID,\n",
    "                                    \"bbox\": [float(x1), float(y1), float(w), float(h)],\n",
    "                                    \"score\": float(sc)\n",
    "                                    })\n",
    "        avg_inf = total_time / processed if processed > 0 else 0.0\n",
    "        info_text = f\"Inf time/frame: {avg_inf:.3f}s, device: {DEVICE}\"\n",
    "        cv2.putText(frame, info_text, (10, height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1, cv2.LINE_AA)\n",
    "        out.write(frame)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    out.release()\n"
   ],
   "id": "9d421ec0e3c49c81",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:39:28.778635Z",
     "start_time": "2025-10-31T21:39:28.775699Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Сохранено в {OUTPUT_VIDEO}. Среднее время инференса на кадр = {total_time/processed:.3f}s (для {processed} кадров).\")",
   "id": "678e7d296fc4ef3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено в C:\\Users\\festa\\PycharmProjects\\object_detect\\crowd_1.mp4. Среднее время инференса на кадр = 0.082s (для 705 кадров).\n"
     ]
    }
   ],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:39:29.606725Z",
     "start_time": "2025-10-31T21:39:28.790652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"instances_Validation.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for ann in data[\"annotations\"]:\n",
    "    x, y, w, h = ann[\"bbox\"]\n",
    "    ann[\"bbox\"] = [x * SCALE, y * SCALE, w * SCALE, h * SCALE]\n",
    "\n",
    "with open(\"instances_scaled.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(\"BBoxes масштабированы под SCALE =\", SCALE)"
   ],
   "id": "4d9c00e7cdd1a3a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBoxes масштабированы под SCALE = 2.0\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:39:30.842074Z",
     "start_time": "2025-10-31T21:39:30.008952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(coco_boxes, f, indent=2)\n",
    "\n",
    "print(\"Результаты сохранены в results.json\")"
   ],
   "id": "30e5f3abd017b2e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты сохранены в results.json\n"
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T21:39:31.109552Z",
     "start_time": "2025-10-31T21:39:30.974144Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"model.pth\")",
   "id": "3235ddea1ed4bbee",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "abdaf84e9794beec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu-env)",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
